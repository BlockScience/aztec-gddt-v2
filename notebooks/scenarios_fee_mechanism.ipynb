{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fee Mechanism Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = \"png\"\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from aztec_gddt.analysis.execute import execute_sim, complexity_desc\n",
    "from aztec_gddt.analysis.visualizations import plot_agg_kpis, plot_inspect_vars\n",
    "from aztec_gddt.analysis.metrics import *\n",
    "from aztec_gddt.scenario_experiments import *\n",
    "\n",
    "import gcsfs\n",
    "fs = gcsfs.GCSFileSystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The **Fee Mechanism** scenario group is a series of simulations designed to help inform the specification of protocol parameters that are expected to impact the fee mechanism, either directly as part of its definition or indirectly by influencing the demand for and/or supply of Aztec transactions services. \n",
    "\n",
    "Each scenario within the group focuses on upon a different aspect of the environment the fee mechanism operates within. For example, the volatility scenario assesses the amplification or attenuation of secondary market price volatility on the base fee, while the shock analysis scenario investigates the dynamics of the base fee when it is perturbed by gas price shocks (i.e. abrupt changes with or without a volatility 'tail'). \n",
    "\n",
    "The underlying mechanisms and many of the protocol parameters are the same across the scenarios within the group--but the different environmental aspects determine which protocol parameters are under particular scrutiny and hence which are \"swept\" across different potential values. Because protocol parameters are under control of the system designer, these parameters of study are denoted \"control parameters\". By contrast, parameters that determine the type of environment, such as the volatility or shock magnitude of a secondary price process, are outside of the direct control of the designer and are denoted \"environmental parameters\". Environmental parameters usually specify 1) the _trend_ of one or more external processes, such as secondary market prices, and 2) the _distribution_ from which an environmental effect is randomly drawn.\n",
    "\n",
    "Different combinations of control and environmental parameter values generate different simulation outcomes. The assessment and analysis of these different outcomes are facilitated by two simulation methodologies:\n",
    "1. Key Performance Indicators (KPIs): also called 'metrics', these variables are measurements that help analyze simulation outcomes. KPIs are assessed according to desired system properties (_success criteria_), usually by comparing a KPI (or a function of several KPIs, as described in #2 below) to a minimum or maximum _threshold value_ within one or more _threshold inequalities_. Threshold inequalities quantify the success criteria specified by stakeholders and provide a means of determining which parameter combinations support simulation outcomes that fulfill these criteria.\n",
    "2. Monte Carlo simulations: as described above, environmental parameters specify trends and random realizations from distributions that are parameterized by one or more environmental parameters. To capture the overall effect of the environment, several different realizations are usually drawn and a full simulation run performed for each. The resulting outcome is a _Monte Carlo_ (or MC) _run_, and robust results are obtained by examining the moments, quantiles etc. of the KPIs across MC runs.\n",
    "\n",
    "## Scenarios\n",
    "\n",
    "1. Volatility: The volatility scenario tests the effect of secondary market volatility on the volatility of the base fee and on the profitability of a sequencer or prover.\n",
    "2. L2 Cost Censorship: The L2 Cost Censorship scenario assesses the relative inclusion of L2 transactions, by simulating user-provided maximum fee per _mana_ values and comparing them to base fee realizations, with the intuition that a transactions will only be included if its maximum fee will at least cover the base fee cost. \n",
    "3. Congestion Shock Analysis: The shock analysis scenario tests the effects of both L2 network congestion and L1 network congestion (represented through L1 gas prices changes) on the base fee dynamics. \n",
    "4. Oracle Sensitivity: The oracle sensitivity scenario tests the sensitivity of the fee mechanism to small errors that may propagate via an oracle channel, where actual values can diverge from those used for computation due to lags (caused by e.g. a slow update frequency relative to block time, and a slower magnitude of change relative to an actual value change).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_spec = experiment_feemech_volatility\n",
    "\n",
    "# # Override default configuration\n",
    "# exp_spec.N_timesteps = 1_000\n",
    "# exp_spec.N_samples = 1\n",
    "# exp_spec.N_config_sample = 40\n",
    "\n",
    "# CONTROL_PARAMS = list(exp_spec.params_swept_control.keys())\n",
    "\n",
    "# sim_df, exec_time = execute_sim(exp_spec.prepare())\n",
    "# agg_df, c_agg_df = retrieve_feature_df(sim_df, CONTROL_PARAMS, exp_spec.relevant_per_trajectory_group_metrics)\n",
    "\n",
    "path = 'gs://aztec-gddt-v2-sim/FM-SG1/2025-01-31T03:53:07Z/'\n",
    "\n",
    "with fs.open(path + 'spec.json', 'r') as fid:\n",
    "    exp_spec = ExperimentParamSpec.from_json(fid.read()) # type: ginore\n",
    "\n",
    "sim_df = pd.read_pickle(path + 'timestep_tensor-0.pkl.gz')\n",
    "agg_df = pd.read_pickle(path + 'trajectory_tensor.pkl.gz')\n",
    "c_agg_df = compute_agg_df(exp_spec.relevant_per_trajectory_group_metrics, agg_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective \n",
    "The current specification of the fee mechanism requires a conversion from _gwei_ to Fee Asset. This implies that secondary market volatility of that asset pair has effects on each realization of the base fee and as such presents an uncertain outcome on quality of service for both end users and service provisioning by sequencers and provers. \n",
    "This scenario tests the propagation of secondary market volatility of the Fee Asset price to 1) the volatility of the base fee, denominated in terms of Fee Asset per _mana_, 2) the profitability of the sequencer, and 3) the profitability of the prover."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Variables: \n",
    ":dart: we should check tthe below variables \n",
    "\n",
    "##### Environmental:\n",
    "Different exchange rate (between the Fee Asset and _gwei_) behaviors are realized over the course of a given environmental scenario. Exchange rate scenarios are modeled as particular shocks, where the exchange rate either:\n",
    "\n",
    "1. Strictly increases at a parameterized maximum change throughout the simulation, or \n",
    "2. Strictly decreases at a parameterized maximum change throughout the simulation, or\n",
    "3. Is realized from random draws from a parameterized distribution, or\n",
    "4. Stagnates without much change throughout the simulation.\n",
    "\n",
    "These scenario 'subgroups' act as proxies for different environmental realizations of secondary market effects on the base fee. \n",
    "\n",
    "##### Protocol: \n",
    "Different protocol parameters are investigated for their impact upon the base fee over the different environmental scenario subgroups described above. As the base fee is computed from various parametrizable components which do not have strong _ex ante_ values, this scenario tests a first group of parameter choices. \n",
    "\n",
    "This group consists of:\n",
    "\n",
    "1. `OVERHEAD_MANA_PER_TX` - Each transaction incurs overhead mana costs of this size, irrespective of any conducted operations. \n",
    "2. `MAXIMUM_MANA_PER_BLOCK` - Each block is limited in *size* by this value, affecting profitability of sequencers, throughput of the network, and the computation of base fees directly. \n",
    "3. `TARGET_MANA_PER_BLOCK` - This value is needed to compute the congestion component of the base fee. \n",
    "4. `MAXIMUM_FEE_JUICE_PER_GWEI_PERCENT_CHANGE_PER_L2_SLOT` - This limits the useable space of real secondary market price updates. In other words, the real secondary market price can fluctuate freely (such as in a flashcrash), while the oracle value used in practice by users is limited in change. Through this the base fee might lag behind in its conversion component when compared to a \"real\" secondary market price value used in computation. \n",
    "5. `MAXIMUM_PROVING_COST_GWEI_PER_MANA_PERCENT_CHANGE_PER_L2_SLOT` - This limits the useable space of real proving cost updates. In other words, the proving cost experienced by provers might differ from the oracle value used in practice by users. Through this the base fee might lag behind in its proving cost component when compared to a \"real\" secondary market price value used in computation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulation input/output per Monte Carlo run:\n",
    "\n",
    "##### Input:\n",
    "For each parameter constellation of interest, we draw a simulated time series of secondary market Fee Asset price used to pay the transaction fee. For random realizations, the distribution is parameterized by the first two moments (mean, variance).\n",
    "\n",
    "##### Output:\n",
    "- $\\mathcal{M}$ Monte Carlo runs indexed by $m$.\n",
    "- Time series of the base fee denominated in Fee Asset per _mana_\n",
    "- Number of empty slots per epoch, for each $m$th Monte Carlo run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sweep Parameters:\n",
    "Refer to theÂ [spreadsheet](https://docs.google.com/spreadsheets/d/1EbW4sEYWb7iCjOYfgivNsLxe1O6ZFYwFSsRQjfiPLTM/edit?gid=955157985#gid=955157985&range=A1)Â for detailed parameter configurations related to staking and slashing mechanisms.\n",
    "\n",
    ":dart: Fill in :dart:\n",
    "\n",
    "##### Control:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_spec.print_control_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Environmental:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_spec.print_env_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulation Behavior:\n",
    "1. A sequencer will not post a block to L1 if the revenue from the block is less than the cost of posting the block.\n",
    "2. A prover will not post a proof to L1 if the revenue from proving is less than the cost of posting the block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Threshold Inequalities:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics:\n",
    "1. **Average relative volatility:** $\\bar{(\\frac{\\sigma_B}{\\sigma_A})}$, where the average is taken over the $\\mathcal{M}$ MC runs of the values $\\sigma_B^m$/$\\sigma_A^m$, $m = 1 , â€¦ ,\\mathcal{M}$, and $\\sigma_A^m$ and $\\sigma_B^m$ are the volatility measures for the ASSET time series and BASE FEE time series for MC run $m$, respectively.\n",
    "\n",
    "     _Interpretation_: A value of the metric greater than 1 indicates that ASSET price volatility is amplified, while a volatility less than 1 indicates that ASSET price volatility is attenuated.\n",
    "\n",
    "2. **Average number of empty block slots** over the $\\mathcal{M}$ MC runs.\n",
    "\n",
    "     _Interpretation_: A large number of empty slots implies that posting blocks to L1 is unprofitable for a sequencer.\n",
    "\n",
    "3. **Average number of unproven epochs** over the $\\mathcal{M}$ MC runs.\n",
    "\n",
    "     _Interpretation_: A large number of unproven epochs implies that posting proofs to L1 is unprofitable for a prover.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computational Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(complexity_desc(exp_spec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation Results \n",
    "\n",
    ":::info\n",
    "See [main doc](https://hackmd.io/@blockscience/B1QKItvEye) for copyable explanations (or referenceable)\n",
    ":::\n",
    "\n",
    "- [ ] :dart: Write descriptive interpretation over the plot below :dart: \n",
    "- [ ] :dart: Generate an analogue plot below for the results :dart: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_inspect_vars(sim_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protocol Parameter Recommendations \n",
    "\n",
    ":::info\n",
    "See [main doc](https://hackmd.io/@blockscience/B1QKItvEye) for copyable explanations (or referenceable)\n",
    ":::\n",
    "\n",
    "- [ ] :dart: Write descriptive interpretation over table :dart: \n",
    "- [ ] :dart: Generate an analogue table below for the results :dart: \n",
    "\n",
    "\n",
    "| Control Parameter | Recommended Range | Unit |\n",
    "| - | - | - |\n",
    "| RELATIVE_TARGET_MANA_PER_BLOCK | tbd | Mana |\n",
    "| MAXIMUM_MANA_PER_BLOCK | tbd | Mana |\n",
    "| MINIMUM_MULTIPLIER_CONGESTION | tbd | Unitless |\n",
    "| UPDATE_FRACTION_CONGESTION | tbd | 1 / Mana |\n",
    "| OVERHEAD_MANA_PER_TX | tbd | Mana |\n",
    "| PROVING_COST_MODIFIER_INITIAL_C | tbd | Mana |\n",
    "| FEE_JUICE_PRICE_MODIFIER_INITIAL_C | tbd | Juice per Gwei |\n",
    "| MAXIMUM_UPDATE_PERCENTAGE_C | tbd | Unitless |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree and Parameter Importance\n",
    "\n",
    ":::info\n",
    "See [main doc](https://hackmd.io/@blockscience/B1QKItvEye) for copyable explanations (or referenceable)\n",
    ":::\n",
    "- [ ] :dart: Write descriptive interpretation over the plot below :dart: \n",
    "- [ ] :dart: Generate an analogue plot below for the results :dart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_agg_kpis(c_agg_df, exp_spec.params_swept_control, exp_spec.relevant_per_trajectory_group_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commentary on Results:\n",
    "\n",
    ":dart: Write anything that comes up to mind based on the interpretation over all the results :dart: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- [ ] ðŸ”« Jakob owns after Danilo wrote commentary on results ðŸ”«"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix:\n",
    "### Parameter Impact on Metrics: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. L2 Cost Censorship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_spec = experiment_feemech_l2_cost_censorship\n",
    "\n",
    "# # Override default configuration\n",
    "# exp_spec.N_timesteps = 1_000\n",
    "# exp_spec.N_samples = 1\n",
    "# exp_spec.N_config_sample = 10\n",
    "\n",
    "# CONTROL_PARAMS = list(exp_spec.params_swept_control.keys())\n",
    "\n",
    "# sim_df, exec_time = execute_sim(exp_spec.prepare())\n",
    "# agg_df, c_agg_df = retrieve_feature_df(sim_df, CONTROL_PARAMS, exp_spec.relevant_per_trajectory_group_metrics)\n",
    "\n",
    "path = 'gs://aztec-gddt-v2-sim/FM-SG2/2025-01-31T03:56:15Z/'\n",
    "\n",
    "with fs.open(path + 'spec.json', 'r') as fid:\n",
    "    exp_spec = ExperimentParamSpec.from_json(fid.read()) # type: ginore\n",
    "\n",
    "sim_df = pd.read_pickle(path + 'timestep_tensor-0.pkl.gz')\n",
    "agg_df = pd.read_pickle(path + 'trajectory_tensor.pkl.gz')\n",
    "c_agg_df = compute_agg_df(exp_spec.relevant_per_trajectory_group_metrics, agg_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective \n",
    "As the fee mechanism can return a different base fee at each timestep, users must specify a maximum fee per _mana_ value they are willing to pay, regardless of the movement of the base fee. This implies that a highly volatile base fee might render a \"reasonably set\" max fee per _mana_ value infeasible in practice--by the time a user's transaction is considered for inclusion in a block, the expected trajectory of the base fee may render the transaction unprofitable.\n",
    "\n",
    "This scenario assesses the relative inclusion of transactions in a block according to sequencer profitability, based upon the _requirement_ that the maximum fee perÂ _mana_Â for any (included) transaction must **at least cover** the estimated base fee cost in a dynamically adjusting environment. By simulating shocks in this environment (which propagate to the fee mechanism computation), insights can be gained on the potential effects of transactions inclusion under different maximum fee per _mana_ and other protocol parameter assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Variables: \n",
    ":dart: we should check tthe below variables \n",
    "\n",
    "##### Environmental:\n",
    "\n",
    "To simulate the effects of different user maximum fee per _mana_ values, a distribution of such values is specified and parameterized by its first two moments (mean, standard deviation).\n",
    "\n",
    "To simulate the transaction block inclusion decision of a sequencer, a specified behavioral assumption is enforced: A transaction will be included if its maximum fee per _mana_ at least covers an expected base fee that is a modified (inflated) value of the latest base fee. This behavioral assumption was provided by the Aztec team to BlockScience for use in this scenario.\n",
    "\n",
    "The secondary market exchange rate, L1 gas prices and proving costs are modeled as particular shocks, where each relevant time series may:\n",
    "\n",
    "1. Strictly increase at a parameterized maximum change throughout the simulation, or \n",
    "2. Strictly decrease at a parameterized maximum change throughout the simulation, or\n",
    "3. Be realized from random draws from a parameterized distribution, or\n",
    "4. Stagnate without much change throughout the simulation.\n",
    "\n",
    "##### Protocol\n",
    "\n",
    "Different protocol parameters are investigated for their impact upon the base fee over the different environmental scenario subgroups described above. As the base fee is computed from various parametrizable components which do not have strong _ex ante_ values, this scenario tests a first group of parameter choices. \n",
    "\n",
    "This group consists of:\n",
    "\n",
    "1. `OVERHEAD_MANA_PER_TX` - Each transaction incurs overhead mana costs of this size, irrespective of any conducted operations. \n",
    "2. `MAXIMUM_MANA_PER_BLOCK` - Each block is limited in *size* by this value, affecting profitability of sequencers, throughput of the network, and the computation of base fees directly. \n",
    "3. `TARGET_MANA_PER_BLOCK` - This value is needed to compute the congestion component of the base fee. \n",
    "4. `MAXIMUM_FEE_JUICE_PER_GWEI_PERCENT_CHANGE_PER_L2_SLOT` - This limits the useable space of real secondary market price updates. In other words, the real secondary market price can fluctuate freely (such as in a flashcrash), while the oracle value used in practice by users is limited in change. Through this the base fee might lag behind in its conversion component when compared to a \"real\" secondary market price value used in computation. \n",
    "5. `MAXIMUM_PROVING_COST_GWEI_PER_MANA_PERCENT_CHANGE_PER_L2_SLOT` - This limits the useable space of real proving cost updates. In other words, the proving cost experienced by provers might differ from the oracle value used in practice by users. Through this the base fee might lag behind in its proving cost component when compared to a \"real\" secondary market price value used in computation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulation input/output per Monte Carlo run:\n",
    "\n",
    "##### Input:\n",
    "For each parameter constellation of interest, we draw simulated time series for:\n",
    "\n",
    "- Secondary market Fee Asset price,\n",
    "- L1 gas price,\n",
    "- Proving cost, and\n",
    "- Transactions with different maximum fee per _mana_ amounts.\n",
    "\n",
    "For random realizations, distributions for the above are parameterized by the first two moments (mean, variance).\n",
    "\n",
    "##### Output:\n",
    "- $\\mathcal{M}$ Monte Carlo runs indexed by $m$.\n",
    "- Time series of the base fee denominated in Fee Asset per _mana_\n",
    "- Transactions included in each block\n",
    "- Transactions dropped from each block\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sweep Parameters:\n",
    "Refer to theÂ [spreadsheet](https://docs.google.com/spreadsheets/d/1EbW4sEYWb7iCjOYfgivNsLxe1O6ZFYwFSsRQjfiPLTM/edit?gid=955157985#gid=955157985&range=A1)Â for detailed parameter configurations related to staking and slashing mechanisms.\n",
    "\n",
    ":dart: Fill in :dart:\n",
    "\n",
    "##### Control:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_spec.print_control_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Environmental:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_spec.print_env_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulation Behavior:\n",
    "\n",
    "**Profitability**\n",
    "- A sequencer will not post a block to L1 if the revenue from the block is less than the cost of posting the block.\n",
    "- A prover will not post a proof to L1 if the revenue from proving is less than the cost of posting the block.\n",
    "\n",
    "**Inflation term**\n",
    "- For each run, the meanÂ $Î¼_B$Â of the distribution of the maximum transaction fee per _mana_ for a blockÂ $B$Â is set using the following rule:\n",
    "$$Î¼_B := (1+\\pi)F_{Bâˆ’1},$$\n",
    "whereÂ $\\pi \\geq 0$Â is an inflation term that is swept over andÂ $F_{Bâˆ’1}$Â is the base fee for the immediately previous block.\n",
    "\n",
    "Intuitively, a transaction with a maximum fee per _mana_ value equal to the mean value $\\mu_B$ will included in a block by a sequencer ifÂ $\\mu_B \\geq F_B$, where $F_B$ is the base fee of the current block, and dropped otherwise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Threshold Inequalities:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics:\n",
    "1. **Average percentage of dropped transactions**:Â $\\bar{(\\frac{T_I}{T_I+T_D})}$, where the average is taken over theÂ $M$Â MC runs of valuesÂ $\\frac{T_I^m}{T_I^m+{T_D^m}}$Â andÂ $T_I^m$Â and $T_D^m$ are the total transactions included and dropped for MC runÂ $m$, respectively.\n",
    "\n",
    "     _Interpretation_: A high value indicates many transactions are dropped, while a low value indicates few values are dropped.\n",
    "\n",
    "2. **Percentage of MC runs above dropped threshold** ([PERCENTAGE_CENSORSHIP_LIMIT_M](https://docs.google.com/spreadsheets/d/1EbW4sEYWb7iCjOYfgivNsLxe1O6ZFYwFSsRQjfiPLTM/edit?gid=1840722092#gid=1840722092&range=A39)): The proportion of all MC runs for which the average percentage of dropped transactions was less than a THRESHOLD AMOUNT.\n",
    "\n",
    "     _Interpretation_: The percentage of Monte Carlo runs where the fraction of L2 transactions censored due to cost remains below a threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computational Complexity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(complexity_desc(exp_spec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation Results \n",
    "\n",
    ":::info\n",
    "See [main doc](https://hackmd.io/@blockscience/B1QKItvEye) for copyable explanations (or referenceable)\n",
    ":::\n",
    "\n",
    "- [ ] :dart: Write descriptive interpretation over the plot below :dart: \n",
    "- [ ] :dart: Generate an analogue plot below for the results :dart: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_inspect_vars(sim_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protocol Parameter Recommendations \n",
    "\n",
    ":::info\n",
    "See [main doc](https://hackmd.io/@blockscience/B1QKItvEye) for copyable explanations (or referenceable)\n",
    ":::\n",
    "\n",
    "- [ ] :dart: Write descriptive interpretation over table :dart: \n",
    "- [ ] :dart: Generate an analogue table below for the results :dart: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree and Parameter Importance\n",
    "\n",
    ":::info\n",
    "See [main doc](https://hackmd.io/@blockscience/B1QKItvEye) for copyable explanations (or referenceable)\n",
    ":::\n",
    "- [ ] :dart: Write descriptive interpretation over the plot below :dart: \n",
    "- [ ] :dart: Generate an analogue plot below for the results :dart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_agg_kpis(c_agg_df, exp_spec.params_swept_control, exp_spec.relevant_per_trajectory_group_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commentary on Results:\n",
    "\n",
    ":dart: Write anything that comes up to mind based on the interpretation over all the results :dart: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- [ ] ðŸ”« Jakob owns after Danilo wrote commentary on results ðŸ”«"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix:\n",
    "### Parameter Impact on Metrics: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Congestion Shock Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_spec = experiment_feemech_shock_analysis\n",
    "\n",
    "# # Override default configuration\n",
    "# exp_spec.N_timesteps = 1_000\n",
    "# exp_spec.N_samples = 1\n",
    "# exp_spec.N_config_sample = 10\n",
    "\n",
    "# CONTROL_PARAMS = list(exp_spec.params_swept_control.keys())\n",
    "\n",
    "# sim_df, exec_time = execute_sim(exp_spec.prepare())\n",
    "# agg_df, c_agg_df = retrieve_feature_df(sim_df, CONTROL_PARAMS, exp_spec.relevant_per_trajectory_group_metrics)\n",
    "\n",
    "path = 'gs://aztec-gddt-v2-sim/FM-SG3/2025-01-31T12:52:12Z/'\n",
    "\n",
    "with fs.open(path + 'spec.json', 'r') as fid:\n",
    "    exp_spec = ExperimentParamSpec.from_json(fid.read()) # type: ginore\n",
    "\n",
    "sim_df = pd.read_pickle(path + 'timestep_tensor-0.pkl.gz')\n",
    "agg_df = pd.read_pickle(path + 'trajectory_tensor.pkl.gz')\n",
    "c_agg_df = compute_agg_df(exp_spec.relevant_per_trajectory_group_metrics, agg_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective \n",
    "The fee mechanism is affected by both:\n",
    "\n",
    "- L1 congestion (through *limited L1 block space*, resulting in high gas and blob gas prices, as well as potential unavailability of settlement), and\n",
    "- L2 congestion (through the *congestion component* of the fee mechanism).\n",
    "\n",
    "These congestions effects are important because the propagation of congestion effects to the base fee can have either _distortionary_ effects, such as amplifying base fee volatility or introducing an unwanted trend, or _regularity_ effects, such as reducing transactions demand during high congestion periods (thereby reducing congestion toward a desired 'baseline').\n",
    "\n",
    "This scenario assesses:\n",
    "1. The stability of the base fee, and\n",
    "2. The effects of its movement upon the degree to which transactions are included or excluded from a block,\n",
    "\n",
    "when congestion shocks are introduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Variables: \n",
    ":dart: we should check the below variables \n",
    "\n",
    "##### Environmental:\n",
    "\n",
    "The simulation of L2 congestion effects is accomplished by introducing a time series for _transactions volume_ that exhibits low or high network congestion. This is modeled by simulating _excursions_ from periods of low volatility to periods of high volatility for a fixed duration of time.\n",
    "\n",
    "The L1 gas price time series, representing the effect of limited L1 block space, is modeled as resulting from particular shocks and may:\n",
    "\n",
    "1. Strictly increase at a parameterized maximum change throughout the simulation, or \n",
    "2. Strictly decrease at a parameterized maximum change throughout the simulation, or\n",
    "3. Be realized from random draws from a parameterized distribution, or\n",
    "4. Stagnate without much change throughout the simulation.\n",
    "\n",
    "\n",
    "##### Protocol: \n",
    "Different protocol parameters are investigated for their impact upon the base fee over the different environmental scenario subgroups described above. As the base fee is computed from various parametrizable components which do not have strong _ex ante_ values, this scenario tests a first group of parameter choices. \n",
    "\n",
    "This group consists of:\n",
    "\n",
    "1. `OVERHEAD_MANA_PER_TX` - Each transaction incurs overhead mana costs of this size, irrespective of any conducted operations. \n",
    "2. `MAXIMUM_MANA_PER_BLOCK` - Each block is limited in *size* by this value, affecting profitability of sequencers, throughput of the network, and the computation of base fees directly. \n",
    "3. `TARGET_MANA_PER_BLOCK` - This value is needed to compute the congestion component of the base fee. \n",
    "4. `MAXIMUM_FEE_JUICE_PER_GWEI_PERCENT_CHANGE_PER_L2_SLOT` - This limits the useable space of real secondary market price updates. In other words, the real secondary market price can fluctuate freely (such as in a flashcrash), while the oracle value used in practice by users is limited in change. Through this the base fee might lag behind in its conversion component when compared to a \"real\" secondary market price value used in computation. \n",
    "5. `MAXIMUM_PROVING_COST_GWEI_PER_MANA_PERCENT_CHANGE_PER_L2_SLOT` - This limits the useable space of real proving cost updates. In other words, the proving cost experienced by provers might differ from the oracle value used in practice by users. Through this the base fee might lag behind in its proving cost component when compared to a \"real\" secondary market price value used in computation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulation input/output per Monte Carlo run:\n",
    "\n",
    "##### Input:\n",
    "\n",
    "For each parameter constellation of interest, we draw simulated time series for:\n",
    "\n",
    "1. L2 transactions volume representing \"low\" and \"high\" network congestion, where \"low\" is parameterized by a distribution with meanÂ $\\mu_L$Â and \"high\" is parameterized by a distribution with meanÂ $\\mu_L + \\Delta_\\mu$, withÂ $\\Delta_\\mu > 0$. The time series exhibits a \"shock\" from low to high L2 congestion for a durationÂ $t_\\mu > 0$, and subsequently returns to low congestion.\n",
    "2. L1 gas prices representing \"low\" and \"high\" costs, where \"low\" is parameterized by a distribution with a meanÂ $\\gamma_L$Â and \"high\" is parameterized by a distribution with a meanÂ $\\gamma_L + \\Delta_\\gamma$, withÂ $\\Delta_\\gamma > 0$. The time series exhibits a \"shock\" from low to high L1 costs for a durationÂ $t_\\gamma > 0$, and subsequently returns to low costs.\n",
    "\n",
    "Realizations of $(\\Delta_\\mu, \\Delta_\\gamma)$ and $(t_\\mu, t_\\gamma)$ are drawn from respective distributions with given (mean, variance) moments. Each pair may exhibit correlated or uncorrelated movements depending upon their respective covariance matrices\n",
    "\n",
    "##### Output:  \n",
    "\n",
    "- $\\mathcal{M}$ Monte Carlo runs indexed by $m$.\n",
    "- Time series of the base fee denominated in Fee Asset per _mana_\n",
    "- Transactions included in each block\n",
    "- Transactions dropped from each block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sweep Parameters:\n",
    "Refer to theÂ [spreadsheet](https://docs.google.com/spreadsheets/d/1EbW4sEYWb7iCjOYfgivNsLxe1O6ZFYwFSsRQjfiPLTM/edit?gid=955157985#gid=955157985&range=A1)Â for detailed parameter configurations related to staking and slashing mechanisms.\n",
    "\n",
    ":dart: Fill in :dart:\n",
    "\n",
    "##### Control:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_spec.print_control_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Environmental:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_spec.print_env_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulation Behavior:\n",
    "1. A sequencer will not post a block to L1 if the revenue from the block is less than the cost of posting the block.\n",
    "2. A prover will not post a proof to L1 if the revenue from proving is less than the cost of posting the block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Threshold Inequalities:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics:\n",
    "1. **Average percentage of excluded transactions**:Â $\\bar{(\\frac{T_I}{T_I+T_E})}$, where the average is taken over theÂ MÂ MC runs of valuesÂ $\\frac{T_I^m}{T_I^m+{T_E^m}}$Â andÂ ${T_I^m}$Â and${T_E^m}$Â are the total transactions included and excluded for MC runÂ $m$, respectively.\n",
    "\n",
    "     _Interpretation_: A high value indicates that the network congestion and/or L1 gas cost shocks impact the base fee to the extent that many otherwise available transactions are not included in a block.\n",
    "\n",
    "\n",
    "2. **Percentage of return to base fee** ([PERCENTAGE_RETURN_TO_BASE_M](https://docs.google.com/spreadsheets/d/1EbW4sEYWb7iCjOYfgivNsLxe1O6ZFYwFSsRQjfiPLTM/edit?gid=1840722092#gid=1840722092&range=A41)): The proportion of MC runs where the base fee returns to within a percentage of the base fee after the shock has concluded.\n",
    "\n",
    "     _Interpretation_: A high percentage indicates that the fee mechanism isÂ _resilient_Â to congestion and/or L1 gas cost shocks, returning to a 'baseline' base fee value after the shock has passed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computational Complexity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(complexity_desc(exp_spec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation Results \n",
    "\n",
    ":::info\n",
    "See [main doc](https://hackmd.io/@blockscience/B1QKItvEye) for copyable explanations (or referenceable)\n",
    ":::\n",
    "\n",
    "- [ ] :dart: Write descriptive interpretation over the plot below :dart: \n",
    "- [ ] :dart: Generate an analogue plot below for the results :dart: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_inspect_vars(sim_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protocol Parameter Recommendations \n",
    "\n",
    ":::info\n",
    "See [main doc](https://hackmd.io/@blockscience/B1QKItvEye) for copyable explanations (or referenceable)\n",
    ":::\n",
    "\n",
    "- [ ] :dart: Write descriptive interpretation over table :dart: \n",
    "- [ ] :dart: Generate an analogue table below for the results :dart: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree and Parameter Importance\n",
    "\n",
    ":::info\n",
    "See [main doc](https://hackmd.io/@blockscience/B1QKItvEye) for copyable explanations (or referenceable)\n",
    ":::\n",
    "- [ ] :dart: Write descriptive interpretation over the plot below :dart: \n",
    "- [ ] :dart: Generate an analogue plot below for the results :dart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_agg_kpis(c_agg_df, exp_spec.params_swept_control, exp_spec.relevant_per_trajectory_group_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commentary on Results:\n",
    "\n",
    ":dart: Write anything that comes up to mind based on the interpretation over all the results :dart: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- [ ] ðŸ”« Jakob owns after Danilo wrote commentary on results ðŸ”«"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix:\n",
    "### Parameter Impact on Metrics: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Oracle Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_spec = experiment_feemech_oracle_sensitivity\n",
    "\n",
    "# Override default configuration\n",
    "exp_spec.N_timesteps = 1_000\n",
    "exp_spec.N_samples = 1\n",
    "exp_spec.N_config_sample = 10\n",
    "\n",
    "CONTROL_PARAMS = list(exp_spec.params_swept_control.keys())\n",
    "\n",
    "sim_df, exec_time = execute_sim(exp_spec.prepare())\n",
    "agg_df, c_agg_df = retrieve_feature_df(sim_df, CONTROL_PARAMS, exp_spec.relevant_per_trajectory_group_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective \n",
    "The fee mechanism includes components relying on oracle-supplied values rather than having direct access to actual values. Considering that oracles might not be updated (and/or *updateable*) in real-time, and that their maximum change per update might be bounded, there can exist delays (or _lags_) between oracle and actual values. As oracle values are used in the fee mechanism, it is important to understand the impact of these lags on base fee dynamics. For example, if the oracle and actual values _diverge_ because of lags, users/sequencers/provers may not have access to a realistic cost/profit calculation when using the base fee. \n",
    "\n",
    "This scenario specifically tests the sensitivity of the fee mechanism to errors propagated through oracle channels, which are external sources of truth not directly controlled by Aztec."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Variables: \n",
    ":dart: we should check the below variables \n",
    "\n",
    "##### Environmental:\n",
    "\n",
    "The simulation of oracle-supplied time series is accomplished by introducing several subgroup scenarios, depending upon the type of oracle data being examined:\n",
    "1. Proving cost oracle data: the oracle time series representing the proving cost, which depends upon the maximum change in the oracle's proving cost (`PROVING_COST_MODIFICATION_E`),\n",
    "2. Fee juice per _gwei_ oracle data: the oracle time series representing the secondary market price of juice, which depends upon the maximum change in the oracle's price (`FEE_JUICE_PRICE_MODIFICATION_E`).\n",
    "\n",
    "Each of these time series may have their maximum change take one of the following forms: \n",
    "\n",
    "1. Strictly increase at a parameterized maximum change throughout the simulation, or \n",
    "2. Strictly decrease at a parameterized maximum change throughout the simulation, or\n",
    "3. Stagnate without much change throughout the simulation.\n",
    "\n",
    "In addition, each time series is subject to a potential _delay_ in its reporting of actual values. This delay is modeled as potentially occurring on a block-by-block basis, and has a protocol-specified minimum value (current 5 blocks).\n",
    "\n",
    "\n",
    "##### Protocol:\n",
    "Different protocol parameters are investigated for their impact upon the base fee over the different environmental scenario subgroups described above. As the base fee is computed from various parametrizable components which do not have strong _ex ante_ values, this scenario tests a first group of parameter choices. \n",
    "\n",
    "This group consists of:\n",
    "\n",
    "1. `OVERHEAD_MANA_PER_TX` - Each transaction incurs overhead mana costs of this size, irrespective of any conducted operations. \n",
    "2. `MAXIMUM_MANA_PER_BLOCK` - Each block is limited in *size* by this value, affecting profitability of sequencers, throughput of the network, and the computation of base fees directly. \n",
    "3. `TARGET_MANA_PER_BLOCK` - This value is needed to compute the congestion component of the base fee. \n",
    "4. `MAXIMUM_FEE_JUICE_PER_GWEI_PERCENT_CHANGE_PER_L2_SLOT` - This limits the useable space of real secondary market price updates. In other words, the real secondary market price can fluctuate freely (such as in a flashcrash), while the oracle value used in practice by users is limited in change. Through this the base fee might lag behind in its conversion component when compared to a \"real\" secondary market price value used in computation. \n",
    "5. `MAXIMUM_PROVING_COST_GWEI_PER_MANA_PERCENT_CHANGE_PER_L2_SLOT` - This limits the useable space of real proving cost updates. In other words, the proving cost experienced by provers might differ from the oracle value used in practice by users. Through this the base fee might lag behind in its proving cost component when compared to a \"real\" secondary market price value used in computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulation input/output per Monte Carlo run:\n",
    "\n",
    "##### Input:\n",
    "For each parameter constellation of interest, we draw simulated time series for one of the following scenario subgroups:\n",
    "\n",
    "1. The proving cost modification (`PROVING_COST_MODIFICATION_E`),\n",
    "2. The fee juice price modification (`FEE_JUICE_PRICE_MODIFICATION_E`), and\n",
    "3. The update frequency of each oracle (`ORACLE_UPDATE_FREQUENCY_E`), which is the probability in any L2 block that the oracle could be updated.\n",
    "\n",
    "Whether or not the oracle is actually updated depends upon its last update time--an oracle value can only be updated if at least `MIN_ORACLE_UPDATE_LAG_C` (set to 5 in the simulations) has passed.\n",
    "\n",
    "##### Output:  \n",
    "- $\\mathcal{M}$ Monte Carlo runs indexed by $m$.\n",
    "- Time series of the base fee denominated in Fee Asset per _mana_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sweep Parameters:\n",
    "Refer to theÂ [spreadsheet](https://docs.google.com/spreadsheets/d/1EbW4sEYWb7iCjOYfgivNsLxe1O6ZFYwFSsRQjfiPLTM/edit?gid=955157985#gid=955157985&range=A1)Â for detailed parameter configurations related to staking and slashing mechanisms.\n",
    "\n",
    ":dart: Fill in :dart:\n",
    "\n",
    "##### Control:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_spec.print_control_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exp_spec.print_env_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_spec.print_env_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulation Behavior:\n",
    "\n",
    "- A sequencer will prefer an oracle environment that provides a higher revenue than other environments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Threshold Inequalities:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics:\n",
    "1. **Average Elasticity of the Base Fee**: Defined as the percentage change in the base fee divided by the percentage change in the oracle parameter, averaged over Monte Carlo runs.\n",
    "\n",
    "     _Interpretation_: A value of the metric greater than 1 indicates that the base fee is sensitive to changes in the oracle parameter, making it more susceptible to spurious errors (as modeled by the distribution that the errors are drawn from). A value less than 1 implies that the base fee is less sensitive to such changes, improving its predictability and 'inoculation' against spurious errors.\n",
    "\n",
    "2. **Sequencer Losses**: Calculated as the average difference between 1) the sequencer's potential revenue at the minimum oracle lag and 2) the actual revenue with an update frequency lagÂ in place. The sequencer's potential revenue is calculated when the update frequency of each oracle (`ORACLE_UPDATE_FREQUENCY_E`) is equal to 1, i.e. when the oracle is always updated at least `MIN_ORACLE_UPDATE_LAG_C` blocks (the minimum update frequency the protocol permits). This is a 'baseline' revenue figure and is interpreted as the sequencer's experience if the oracle were not subject to more than the stipulated minimum lag. \n",
    "\n",
    "     _Interpretation_:Â A large positive value indicates that the sequencer has been negatively affected by oracle lag over and above the protocol-imposed minimum lag. Conversely, a negative value means that the sequencer actually benefited from the lag (this may be impossible given the way the base fee is computed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computational Complexity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(complexity_desc(exp_spec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation Results \n",
    "\n",
    ":::info\n",
    "See [main doc](https://hackmd.io/@blockscience/B1QKItvEye) for copyable explanations (or referenceable)\n",
    ":::\n",
    "\n",
    "- [ ] :dart: Write descriptive interpretation over the plot below :dart: \n",
    "- [ ] :dart: Generate an analogue plot below for the results :dart: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_inspect_vars(sim_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protocol Parameter Recommendations \n",
    "\n",
    ":::info\n",
    "See [main doc](https://hackmd.io/@blockscience/B1QKItvEye) for copyable explanations (or referenceable)\n",
    ":::\n",
    "\n",
    "- [ ] :dart: Write descriptive interpretation over table :dart: \n",
    "- [ ] :dart: Generate an analogue table below for the results :dart: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree and Parameter Importance\n",
    "\n",
    ":::info\n",
    "See [main doc](https://hackmd.io/@blockscience/B1QKItvEye) for copyable explanations (or referenceable)\n",
    ":::\n",
    "- [ ] :dart: Write descriptive interpretation over the plot below :dart: \n",
    "- [ ] :dart: Generate an analogue plot below for the results :dart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_agg_kpis(c_agg_df, exp_spec.params_swept_control, exp_spec.relevant_per_trajectory_group_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commentary on Results:\n",
    "\n",
    ":dart: Write anything that comes up to mind based on the interpretation over all the results :dart: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- [ ] ðŸ”« Jakob owns after Danilo wrote commentary on results ðŸ”«"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix:\n",
    "### Parameter Impact on Metrics: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
